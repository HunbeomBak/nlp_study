{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tochtext 튜토리얼 - 영어\n",
    "## 1. 데이터셋 분리  \n",
    "### 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dataset\\\\IMDb_Reviews.csv', <http.client.HTTPMessage at 0x2419ecb31c0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"dataset\\IMDb_Reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset\\IMDb_Reviews.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 개수 : {}'.format(len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습데이터와 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:25000]\n",
    "test_df = df[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./dataset/train_data.csv\", index=False)\n",
    "test_df.to_csv(\"./dataset/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 필드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchtext.data는 필드(Field)라는 도구를 제공하여 앞으로 어떤 전처리를 할 것인지 정의할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 텍스트를 위한 TEXT 객체\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  #fix_length=20\n",
    "                  fix_length=150 )\n",
    "\n",
    "# 레이블 데이터를 위한 LABEL 객체\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sequential : 시퀀스 데이터 여부. (True가 기본값)\n",
    "- use_vocab : 단어 집합을 만들 것인지 여부. (True가 기본값)\n",
    "- tokenize : 어떤 토큰화 함수를 사용할 것인지 지정. (string.split이 기본값)\n",
    "- lower : 영어 데이터를 전부 소문자화한다. (False가 기본값)\n",
    "- batch_first : 미니 배치 차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부. (False가 기본값)\n",
    "- is_target : 레이블 데이터 여부. (False가 기본값)\n",
    "- fix_length : 최대 허용 길이. 이 길이에 맞춰서 패딩 작업(Padding)이 진행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 만들기\n",
    "- TabularDataset은 데이터를 불러오면서 필드에서 정의했던 토큰화 방법으로 토큰화를 수행\n",
    "- 소문자화 같은 기본적인 전처리도 함께 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='.', train='./dataset/train_data.csv', test='./dataset/test_data.csv', format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- path : 파일이 위치한 경로.\n",
    "- format : 데이터의 포맷.\n",
    "- fields : 위에서 정의한 필드를 지정. 첫번째 원소는 데이터 셋 내에서 해당 필드를 호칭할 이름, 두번째 원소는 지정할 필드.\n",
    "- skip_header : 데이터의 첫번째 줄은 무시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 25000\n",
      "테스트 샘플의 개수 : 25000\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vars()를 통해서 주어진 인덱스의 샘플을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['my', 'family', 'and', 'i', 'normally', 'do', 'not', 'watch', 'local', 'movies', 'for', 'the', 'simple', 'reason', 'that', 'they', 'are', 'poorly', 'made,', 'they', 'lack', 'the', 'depth,', 'and', 'just', 'not', 'worth', 'our', 'time.<br', '/><br', '/>the', 'trailer', 'of', '\"nasaan', 'ka', 'man\"', 'caught', 'my', 'attention,', 'my', 'daughter', 'in', \"law's\", 'and', \"daughter's\", 'so', 'we', 'took', 'time', 'out', 'to', 'watch', 'it', 'this', 'afternoon.', 'the', 'movie', 'exceeded', 'our', 'expectations.', 'the', 'cinematography', 'was', 'very', 'good,', 'the', 'story', 'beautiful', 'and', 'the', 'acting', 'awesome.', 'jericho', 'rosales', 'was', 'really', 'very', 'good,', \"so's\", 'claudine', 'barretto.', 'the', 'fact', 'that', 'i', 'despised', 'diether', 'ocampo', 'proves', 'he', 'was', 'effective', 'at', 'his', 'role.', 'i', 'have', 'never', 'been', 'this', 'touched,', 'moved', 'and', 'affected', 'by', 'a', 'local', 'movie', 'before.', 'imagine', 'a', 'cynic', 'like', 'me', 'dabbing', 'my', 'eyes', 'at', 'the', 'end', 'of', 'the', 'movie?', 'congratulations', 'to', 'star', 'cinema!!', 'way', 'to', 'go,', 'jericho', 'and', 'claudine!!'], 'label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('text', <torchtext.data.field.Field object at 0x00000242050B2670>), ('label', <torchtext.data.field.Field object at 0x00000242050B2F70>)])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.fields.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vocabulary 만들기\n",
    "정의한 필드에 .build_vocab() 도구를 사용하면 단어 집합을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 10002\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=10, max_size=10000)\n",
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_freq : 단어 집합에 추가 시 단어의 최소 등장 빈도 조건을 추가.\n",
    "- max_size : 단어 집합의 최대 크기를 지정\n",
    "\n",
    "생성된 단어 집합 내의 단어들은 .stoi를 통해서 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEXT.vocab.stoi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터로더\n",
    "- 데이터로더는 데이터셋에서 미니 배치만큼 데이터를 로드하게 만들어주는 역할\n",
    "- 토치텍스트에서는 Iterator를 사용하여 데이터로더를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 크기를 5로 정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 5000\n",
      "테스트 데이터의 미니 배치 수 : 5000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
    "test_loader = Iterator(dataset=test_data, batch_size = batch_size)\n",
    "\n",
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터 모두 미니 배치의 수가 5,000개인데 이는 25,000개의 샘플을 배치 크기 5씩 묶어주었기 때문\n",
    "\n",
    "첫번째 미니 배치를 받아와서 batch라는 변수에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n",
      "tensor([[   9,   83,  441,   48,  259,  395, 3646,   10,   20,    7,    2,  246,\n",
      "          404,    5, 1799, 2296,   19,  138,   48,   14,  306,    0,    0,   13,\n",
      "          159,  115,   43,  418,   19,    3,  265,    5, 2672, 5307,   18,    0,\n",
      "           53,  411,  743,   10,  118,   43, 1399,    4, 1557,  905, 4105,  294,\n",
      "          305,    0, 5509,   12,   21,   59,  768,    7, 3280,  405, 9791,   13,\n",
      "          159,   98,    2,   59,  313,    2,    0, 1471, 1545,   19,    2, 2156,\n",
      "          246,  127,    5,   36,   84,    7,   12,   59,  974,   40,   38,   89,\n",
      "           75, 1057,    6,  148,   10, 3084,   29,  225,    0,   95,   11,   19,\n",
      "            0,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [  10,   25,   14,    3, 2148,   34,  384,    6, 5185, 8817,   17,  424,\n",
      "           34,  214,  360, 2591,    5,  318,    0,   23, 3086,   17,    0,    4,\n",
      "            2, 1439,   15,  108,   15,    2, 5536, 2445,   10,  837,  107,   84,\n",
      "           16,    2, 3303,    5, 5253, 9948, 2282,   35, 7963,  128,  295,  395,\n",
      "            8,    2,   25,   17,   21,    0,  262, 4739, 9036, 6049,    4, 2263,\n",
      "            2,  339,   23,  105, 3882,  243,    6,    0,  101,   15, 4197, 5253,\n",
      "           40,   15,   46,  174, 5359,    0,  100,    5,    2,  424,   23, 4257,\n",
      "            0, 2361,    0,  179, 4661,    0,   40, 2517,    0,   59,    0,    0,\n",
      "            4, 2261,  178,  655, 3698, 4698,    5,    0,  210, 3043,   31,  712,\n",
      "            3,  107,    0,  907,  107,    0,    0,   23,    0,  538,    2,    0,\n",
      "           37,   47,    5, 1176,    0,    5,  890,    0,  128,  100,    5,    2,\n",
      "         3305,    4, 2879, 3544, 7196,    0,  421, 1113,  316,    5, 4054,    0,\n",
      "           19,   46,    5, 5253,    0,  859],\n",
      "        [ 136, 8460,   34,    3, 3859,    5,    3,    0,    2, 9383,    0, 6775,\n",
      "            0,    0, 1529, 2562,    0,    0,    0,    2,    0,    5,    2,  989,\n",
      "         3189,   12,    7,    0,    2, 1427, 1782,    4,   64,   64,   32, 2515,\n",
      "           17,    3,    0,    8,    0,    0,    0,    4,    7, 2693,    6,  216,\n",
      "           16,    2,  989, 3189,   17,    2,  871,   12,    7,    0,    2,    0,\n",
      "            4, 2608,   34,    0,    6, 9050, 3510, 3499,    0,    4,    2,    0,\n",
      "           34,    0,  856, 4639, 5293,    0,    0,   17,    2, 1891,    0, 1026,\n",
      "         5831,    0,    0,    0,    4,   57, 5652,    0,  247,   21,  593,    0,\n",
      "          101,   50,    2, 9383,  697,    0,    0,    0, 2088,    2,  989, 3189,\n",
      "         9306, 7744,    5,    0,   13,    0,    0,    7,    3,   56,   18, 1041,\n",
      "          989,  561,   31, 8620,    0,    2,   77,  275,    2, 6466,    5,    2,\n",
      "         3175,    4,    0,  402, 1913,   16,    0,    2,    0,  143,    2, 8720,\n",
      "         4649, 9649,    4,    0,    2,  533],\n",
      "        [  32, 1446,  161,    0,    0,   41,    3,    0,  914,   17,   21,    0,\n",
      "          397,    0,    0,   57, 4861,    3,  298,    0,    0,  102, 2935, 1006,\n",
      "           18,   57,  176,  616,    2, 1804,   76,   11,   54, 2573,   45, 1954,\n",
      "            6,    0, 1778, 7004,    0,   38,    0, 1697, 6294,   12,   27,  398,\n",
      "           50,   27, 2106,   12,  168,  298,   14, 2935,    4,  556, 3960,   59,\n",
      "          332,   32,  595, 1305,  244, 1036,    4, 2674,    6,   26, 6281,    2,\n",
      "           82,    0, 1397,    0,    6, 1398,   19,    2, 1698,  319,    6,  101,\n",
      "           31,    0,  108,  324,   99, 2903, 3017, 2814,  396,    0,    0,   15,\n",
      "           33,    0,   13,  254,  705,  543,    6,  328,    2,  581,    0,    3,\n",
      "         3788,  454, 6681,    0,   50,   27,  824,    2,   82,    0,    0,   57,\n",
      "         1303,    0,    6,   48, 6396,   18, 4528,    6,  343, 2322,   16,    2,\n",
      "         3665,   18,   97,    0,  607,  368,    8,    0,  378,    6, 3331,    2,\n",
      "         1501,    0,    4,   70, 1749,  143],\n",
      "        [ 100,   89,   37,    6,  251,    6,   10,  269,   20,   50, 7984,   17,\n",
      "            2, 4478,    0,    5,    0,   47,   52,   12,  905,  117,    8,  236,\n",
      "           90, 2083,  127,  745,   98,    0,    0,   14, 1107,   18,  189,  168,\n",
      "            0,    2,   20, 2743,   19,    3,    0,    4,    0,    0,   12,  853,\n",
      "         2844,  234,  188,    0,    6,    0,    0,    2,   77,    7,    0,  366,\n",
      "            0, 4084,   15,   11,  114,   19,    2,    0, 3721,    6,  234, 2747,\n",
      "            0,   31,  134,  522,    0,    0,   13,    0,  247, 2537,    6,  760,\n",
      "            0,    4,    0,   15,    2, 1454,  251,    8,    2,    0,  694,    6,\n",
      "         1366,    0,  480,   70,   36,  367,  101,   15,    0,    2,    0,    8,\n",
      "            0,    4,   15,    2, 6312,    0,    8, 4720,    0,  106,   27,  446,\n",
      "          195,   36,    3,    0, 5548,   31, 3880,    2,  994,   47,    5, 2794,\n",
      "            0,  156,   91, 3976, 2361,  134,    5,  195,   35,  310,    0,   19,\n",
      "            3, 2190,    0,   12,   87,  199]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # 첫번째 미니배치\n",
    "print(type(batch))\n",
    "print(batch.text) #첫번째 미니 배치의 text 필드를 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 샘플의 길이는 20의 길이를 가지는데, 이는 앞서 초기에 필드를 정의할 때 fix_length를 20으로 정해주었기 때문 => 하나의 미니 배치의 크기는 (배치 크기 × fix_length)\n",
    "- 단어는 단어 집합에서 정해진대로 각 단어에 맵핑되는 고유한 정수로 변환된 상태\n",
    "- 샘플의 중간, 중간에는 숫자 0이 존재하는데 이는  < unk > 토큰의 번호로 단어 집합에 포함되지 못한 단어들은 < unk >라는 토큰으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < pad >토큰이 사용되는 경우\n",
    "-  fix_length를 20이 아니라 150으로 정의하고 진행\n",
    "- 샘플의 뒷 부분이 < pad >의 번호였던 숫자 1로 채워짐\n",
    "- 서로 다른 길이의 샘플들을 동일한 길이로 맞춰추는 padding 작업이 진행됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 956,    2,  680, 2068,   23,   95,    5,    7,   10, 5622,    5,    2,\n",
      "           0, 2244,   31,    3, 2980,    0,    0,    0,    4,   21, 1141,    0,\n",
      "        5481,    0,    0,  560,    6,    0,    3, 2312,  418,   19, 1209, 5212,\n",
      "           0,   13,  721, 4695,   25,   16,   81,  389,    4,    3,    0,  733,\n",
      "           5,    2,  232,    5, 3615, 5084,  102, 4978,    8,    2,   51, 2119,\n",
      "         127,    5,    2,    0, 6042,    5,    2,    0,    5,    0,    8,  293,\n",
      "         575,  223,   11,   14,    2,   59,    0,   25,    6, 1310,    3,  119,\n",
      "         551,    0,   13,    0,    0,    7,    2,  936,    0,   35,  244,    6,\n",
      "           2,  187,  752,  979,    6,  152,  430,   32,  771,  111,    6,   90,\n",
      "         330,   50,   33,  549,  128,   21, 5306,   18,  560,  607,    2,  752,\n",
      "           7,    3, 1386,  327,   17,   60, 3435,    0,   16,   21,    0,    0,\n",
      "          31,    3, 1141,    0,    0,    0,   27,  253,  143,    3,  265,    5,\n",
      "           0, 3080,   12,  545,  101,    0])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # 첫번째 미니배치\n",
    "print(batch.text[0]) # 첫번째 미니배치 중 첫번째 샘플"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch_first\n",
    "토치텍스트에서 필드정의할 때 batch_first를 True로 한 경우와 False를 한 경우를 비교\n",
    "- True : torch.Size([5, 20])\n",
    "- False : torch.Size([20, 5]) => 미니 배치의 크기는 (fix_length × 배치 크기)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

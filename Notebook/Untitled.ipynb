{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 글로브(Global Vectors for Word Representation, GloVe)\n",
    "- 운트 기반과 예측 기반을 모두 사용하는 방법\n",
    "- 존의 카운트 기반의 LSA(Latent Semantic Analysis)와 예측 기반의 Word2Vec의 단점을 보완\n",
    "\n",
    "\n",
    "## 기존 방법론에 대한 비판\n",
    "- LSA\n",
    "    - 각 단어의 빈도수를 카운트 한 행렬이라는 전체적인 통계 정보를 입력으로 받아 차원을 축소(Truncated SVD)하여 잠재된 의미를 끌어내는 방법\n",
    "    - 카운트 기반으로 코퍼스의 전체적인 통계 정보를 고려\n",
    "    - 왕:남자 = 여왕:? (정답은 여자)와 같은 단어 의미의 유추 작업(Analogy task)에는 성능이 떨어짐\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "- Word2Vec\n",
    "    - 실제값과 예측값에 대한 오차를 손실 함수를 통해 줄여나가며 학습하는 예측 기반의 방법\n",
    "    - 예측 기반으로 단어 간 유추 작업에는 LSA보다 뛰어남\n",
    "    - 임베딩 벡터가 윈도우 크기 내에서만 주변 단어를 고려 => 퍼스의 전체적인 통계 정보를 반영하지 못함\n",
    "    \n",
    "## 윈도우 기반 동시 등장 행렬(Window based Co-occurrence Matrix)\n",
    "- 단어의 동시 등장 행렬\n",
    "    -  행과 열을 전체 단어 집합의 단어들로 구성하고, i 단어의 윈도우 크기(Window Size) 내에서 k 단어가 등장한 횟수를 i행 k열에 기재한 행렬\n",
    "    \n",
    "    \n",
    "## 동시 등장 확률(Co-occurrence Probability)\n",
    "- 동시 등장 확률 P(k | i)는 동시 등장 행렬로부터 특정 단어 i의 전체 등장 횟수를 카운트하고, 특정 단어 i가 등장했을 때 어떤 단어 k가 등장한 횟수를 카운트하여 계산한 조건부 확률\n",
    "- P(k | i) 에서 i를 중심 단어(Center Word), k를 주변 단어(Context Word)라고 했을 때, 동시 등장 행렬에서 중심 단어 i의 행의 모든 값을 더한 값을 분모로 하고 i행 k열의 값을 분자로 한 값\n",
    "\n",
    "## 손실 함수(Loss function)\n",
    "- GloVe의 목표 : 임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서의 동시 등장 확률이 되도록 만드는 것\n",
    "\n",
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
